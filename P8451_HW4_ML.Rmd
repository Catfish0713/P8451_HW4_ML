---
title: "P8451_HW4_ML"
author: "Ruixi Li"
date: "2024-02-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```


# Part I: Implementing a Simple Prediction Pipeline

The New York City Department of Health administered a questionnaire on general health and physical activity among residents. Using the dataset class4_p1.csv, fit and evaluate two prediction models using **linear regression**. The aim of the models are to predict the number of days in a month an individual reported having good physical health (feature name: **healthydays**). A codebook is provided so you can look-up the meaning and values of each feature in the dataset. (Note the codebook lists information on features that are not included in your dataset).

Your analytic pipeline should include the following:

## 1. Data Cleaning

```{r load_packages, echo=FALSE}
library(ggbiplot)
library(caret)
```


```{r data_cleaning, message=FALSE, warning=FALSE}
library(tidyverse)
# Read data
hw4data = read_csv("class4_p1.csv")
set.seed(111)

# View the datatypes and summary statistics of the whole dataset
skimr::skim(hw4data)

# Rename and datatype conversion
var.names = c("id", "hypertension", "diabetes", "asthma", "bmi", "tobacco", "alcohol", "pa_chores_min", "pa_walk_day", "pa_self", "diet", "agegrp", "gender", "race","nationality", "fincome", "healthyday")
hw4data = hw4data |>
  set_names(var.names) |>
  mutate(across(-c(5,8,9,17), function(x) as.factor(x)))

hw4data |> Amelia::missmap(main = "Missing values vs observed")

hw4data = hw4data|> 
  select(-id) |> 
  drop_na()

hw4data |> Amelia::missmap(main = "Missing values vs observed")
# it's necessary to make sure that directly drop NAs won't cause bias

```

## 2. Data partition

```{r data_partition}
# Creating balanced partitions in the data
train.index = createDataPartition(hw4data$healthyday, p = 0.7, list = FALSE)

train = hw4data[train.index, ]
test = hw4data[-train.index, ]

# I should check the independence of each variable
```

## 3. Fit two models

There are lots of methods to fit my models. I have thought about using lasso regression to do the auto-selection of predictors and handle multicollinearity. But lasso regression doesn't work well with categorical variables in terms of both feature selection and prediction accuracy. It needs One-hot encoding of the categorical data and ignore the grouping effect. However, group lasso may be a good alternative for robust feature selection although at the cost of prediction accuracy. (Lack of Robustness of Lasso and Group Lasso with Categorical Predictors: Impact of Coding
Strategy on Variable Selection and Prediction https://escholarship.org/content/qt40b200z6/qt40b200z6_noSplash_c3819f1c49cdc6380c6ae5b0ac0af41d.pdf?t=qaj586) 

Here, I would build the two models based on my knowledge.

```{r model_training}
# Avoid overfitting
control = trainControl(method="repeatedcv", number=10, repeats=10, summaryFunction=defaultSummary)

# Train models
model1_train = train(healthyday ~ hypertension + pa_walk_day, data = train, method = "lm", trControl = control)
model2_train = train(healthyday ~ hypertension + diabetes + asthma + alcohol + pa_walk_day + pa_self + diet + agegrp + race + fincome, data = train, method = "lm", trControl = control)
```

* model1: healthyday ~ hypertension + pa_walk_day
* model2: healthyday ~ hypertension + diabetes + asthma + alcohol + pa_walk_day + 
    pa_self + diet + agegrp + race + fincome

## 4. Model Evaluation

```{r model_evaluation}
# Predictions for models
predictions1 = predict(model1_train, test)
predictions2 = predict(model2_train, test)

# Evaluation using Mean Squared Error (MSE)
mse1 = mean((predictions1 - test$healthyday)**2/nrow(test))
mse2 = mean((predictions2 - test$healthyday)**2/nrow(test))

model1_result = bind_rows(train = predictions1, test = test$healthyday, .id = "split")
model2_result = bind_rows(train = predictions2, test = test$healthyday, .id = "split")
result = bind_rows(model1 = model1_result, model2 = model2_result, .id = "model")


result = result |> 
  mutate(residual = train - test)

result |> 
  ggplot(aes(x = model, y = residual)) + geom_violin()



```

* Mean squared error (MSE) for model1(`r mse1`)< model2(`r mse2`), and the residual plot shows that both models have residuals that center around zero, which is good. The spread of the residuals (the range from top to bottom of the violin) seems similar for both models, suggesting that they have a similar variance in their predictions. However, it looks like Model 2 might have a slightly tighter distribution, indicating more consistent predictions. So, model2 is the preferred prediction model using MSE evaluation.

## 5. Implementing setting

My final model: healthyday ~ hypertension + diabetes + asthma + alcohol + pa_walk_day + 
    pa_self + diet + agegrp + race + fincome can be used to predict the number of days in a month an individual reported having good physical health through a comprehensive evaluation of medical conditions, life habits and socioeconomic factors. This insight can guide targeted health interventions and resource allocation to improve the general well-being of the population in NYC.




# Part II: Conducting an Unsupervised Analysis

Using the dataset from the Group assignment Part 3 (USArrests), identify clusters using hierarchical analysis.

## 6. Hierarchical clustering analysis

```{r}
library(factoextra)
library(cluster)
# Load data
data("USArrests")

# look at the structure and summary
skimr::skim(USArrests)

# Check means and SDs to determine if scaling is necessary
USArrests |>
  summarise_all(mean, na.rm = TRUE) |>
  print()

USArrests |>
  summarise_all(sd, na.rm = TRUE) |>
  print()
# need standardization

# Centering and Scaling
set.up.preprocess = preProcess(USArrests, method = c("center", "scale"))

# Output pre-processed values
transformed.vals = predict(set.up.preprocess, USArrests)




set.seed(111)

# Hierarchical clustering using Complete Linkage, 
clusters.hcut=hcut(transformed.vals, k=4, hc_func="hclust", hc_method="complete", hc_metric="euclidian")

clusters.hcut$size

# Plot the obtained dendrogram
fviz_dend(clusters.hcut, rect=TRUE)
fviz_cluster(clusters.hcut)



```


## 7. Determine the optimal number of clusters

```{r gap_statistics}
# Plot gap statistic graph
gap_stat = clusGap(transformed.vals, FUN = hcut, hc_method="complete", K.max = 10, B = 50)
fviz_gap_stat(gap_stat)
```


## 8. Describe the composition of each cluster

```{r clster_estimate}

input.feature.vals=cbind(transformed.vals,cluster=clusters.hcut$cluster)

input.feature.vals |>
  group_by(cluster) |>
  summarise_all(mean)
```

* 

## 9. Research Questions




## 10. Repeat analysis with different parameters

```{r}
clusters.hcut<-hcut(transformed.vals, k=4, hc_func="hclust", hc_method="single", hc_metric="euclidian")

clusters.hcut$size
fviz_dend(clusters.hcut, rect=TRUE)
fviz_cluster(clusters.hcut)

gap_stat <- clusGap(transformed.vals, FUN = hcut, hc_method="single", K.max = 10, B = 50)
fviz_gap_stat(gap_stat)

input.feature.vals<-cbind(transformed.vals,cluster=clusters.hcut$cluster)

input.feature.vals %>%
  group_by(cluster) %>%
  summarise_all(mean)
```

* Yes, the cluster changed.
